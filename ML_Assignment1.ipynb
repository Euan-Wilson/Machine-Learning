{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 35 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Row_ID          30000 non-null  float64\n",
      " 1   Household_ID    30000 non-null  float64\n",
      " 2   Vehicle         30000 non-null  float64\n",
      " 3   Calendar_Year   30000 non-null  float64\n",
      " 4   Model_Year      30000 non-null  float64\n",
      " 5   Blind_Make      30000 non-null  object \n",
      " 6   Blind_Model     30000 non-null  object \n",
      " 7   Blind_Submodel  30000 non-null  object \n",
      " 8   Cat1            30000 non-null  object \n",
      " 9   Cat2            30000 non-null  object \n",
      " 10  Cat3            30000 non-null  object \n",
      " 11  Cat4            30000 non-null  object \n",
      " 12  Cat5            30000 non-null  object \n",
      " 13  Cat6            30000 non-null  object \n",
      " 14  Cat7            30000 non-null  object \n",
      " 15  Cat8            30000 non-null  object \n",
      " 16  Cat9            30000 non-null  object \n",
      " 17  Cat10           30000 non-null  object \n",
      " 18  Cat11           30000 non-null  object \n",
      " 19  Cat12           30000 non-null  object \n",
      " 20  OrdCat          30000 non-null  float64\n",
      " 21  Var1            30000 non-null  float64\n",
      " 22  Var2            30000 non-null  float64\n",
      " 23  Var3            30000 non-null  float64\n",
      " 24  Var4            30000 non-null  float64\n",
      " 25  Var5            30000 non-null  float64\n",
      " 26  Var6            30000 non-null  float64\n",
      " 27  Var7            30000 non-null  float64\n",
      " 28  Var8            30000 non-null  float64\n",
      " 29  NVCat           30000 non-null  object \n",
      " 30  NVVar1          30000 non-null  float64\n",
      " 31  NVVar2          30000 non-null  float64\n",
      " 32  NVVar3          30000 non-null  float64\n",
      " 33  NVVar4          30000 non-null  float64\n",
      " 34  Claim_Amount    30000 non-null  float64\n",
      "dtypes: float64(19), object(16)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# First need to import the libraries and the data into a dataframe using pandas\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "# Seeing all the missing data\n",
    "missing_values = [\"?\" or \" \"]\n",
    "insurance_claim_data = pd.read_csv('./data/train.csv', na_values=missing_values, encoding= 'unicode_escape')\n",
    "insurance_claim_data.shape\n",
    "# Need to transform some of the variables from int64 to float64\n",
    "for i in insurance_claim_data:\n",
    "    if(insurance_claim_data[i].dtype == np.int64):\n",
    "        insurance_claim_data[i] = insurance_claim_data[i].astype('float64')\n",
    "for i in insurance_claim_data:    \n",
    "    if(insurance_claim_data[i].dtype == np.float64):\n",
    "        insurance_claim_data[i].fillna(insurance_claim_data[i].median(), inplace=True)\n",
    "    else:\n",
    "        insurance_claim_data[i].fillna(insurance_claim_data[i].mode()[0], inplace=True)\n",
    "        \n",
    "insurance_claim_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <Center> Data Preprocessing </Center> </b> <br>\n",
    "(1a) <b>The dataset has several fields with missing data. Choose a method to deal with missing data and justify your choice</b> <br> <br>\n",
    "Most features have a small percentage of missing data values. The missing values will be imputed by replacing them with the mode of the categorical variables and the median of the continuous variables. This method prevents the loss of data which would occur when removing the rows containing missing values. As a result, this method was chosen as it helps to retain a large dataset so that all the instances can be fairly represented when building the predictive model.<br>\n",
    "The median will be used for continuous variables as unlike the mean this value cannot be skewed by outliers so it is more suitable for imputing the values for this dataset. With the mode used to replace the missing values for the categorical variables. This is excluding some of the categorical variables such as Cat2, Cat4, Cat5 and Cat7. These features contain a very large proportion of missing values (ranging from approximately 33-50%). As a result these features will be ignored to prevent the feature space from being too large.  An alternative would be to remove the rows containing missing values. However, this could result in the loss of a lot of data, especially for the test set which would hinder the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 24 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Row_ID         30000 non-null  float64\n",
      " 1   Household_ID   30000 non-null  float64\n",
      " 2   Vehicle        30000 non-null  float64\n",
      " 3   Calendar_Year  30000 non-null  float64\n",
      " 4   Model_Year     30000 non-null  float64\n",
      " 5   Cat3           30000 non-null  object \n",
      " 6   Cat6           30000 non-null  object \n",
      " 7   Cat8           30000 non-null  object \n",
      " 8   Cat9           30000 non-null  object \n",
      " 9   OrdCat         30000 non-null  float64\n",
      " 10  Var1           30000 non-null  float64\n",
      " 11  Var2           30000 non-null  float64\n",
      " 12  Var3           30000 non-null  float64\n",
      " 13  Var4           30000 non-null  float64\n",
      " 14  Var5           30000 non-null  float64\n",
      " 15  Var6           30000 non-null  float64\n",
      " 16  Var7           30000 non-null  float64\n",
      " 17  Var8           30000 non-null  float64\n",
      " 18  NVCat          30000 non-null  object \n",
      " 19  NVVar1         30000 non-null  float64\n",
      " 20  NVVar2         30000 non-null  float64\n",
      " 21  NVVar3         30000 non-null  float64\n",
      " 22  NVVar4         30000 non-null  float64\n",
      " 23  Claim_Amount   30000 non-null  float64\n",
      "dtypes: float64(19), object(5)\n",
      "memory usage: 5.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Got rid of more variables as I couldn't fix the problem with different values in the training & test data\n",
    "insurance_claim_data = insurance_claim_data.drop(['Cat1','Cat2', 'Cat4', 'Cat5', 'Cat7', 'Cat10', \\\n",
    "                                        'Cat11', 'Cat12', 'Blind_Submodel','Blind_Make','Blind_Model'], axis=1)\n",
    "list(insurance_claim_data.columns.values)\n",
    "insurance_claim_data.info()\n",
    "insurance_claim_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Splitting the training set into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "ic_train_set, ic_test_set = train_test_split(insurance_claim_data, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1b) <b> Convert categorical values to a suitable representation. Notice that there are many categorical variables in the dataset. \n",
    "If you use all the categorical variables you will end up with a large feature space. \n",
    "Feel free to ignore categorical variables that will increase your feature space considerably \n",
    "but use at least five categorical variables </b> <br> <br>\n",
    "\n",
    "OneHotEncoder() can be used to transform the categorical variables to a one-hot encoding representation which is suitable as it gives a higher-dimensional binary representation for each value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                 ['Row_ID', 'Household_ID', 'Vehicle',\n",
       "                                  'Calendar_Year', 'Model_Year', 'Var1', 'Var2',\n",
       "                                  'Var3', 'Var4', 'Var5', 'Var6', 'Var7',\n",
       "                                  'Var8', 'NVVar1', 'NVVar2', 'NVVar3',\n",
       "                                  'NVVar4', 'OrdCat']),\n",
       "                                ('cat', OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['Cat3', 'Cat8', 'Cat9', 'Cat6', 'NVCat'])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "features_cat = ['Cat3', 'Cat8', \\\n",
    "                 'Cat9', 'Cat6', 'NVCat']\n",
    "features_num = ['Row_ID', 'Household_ID', 'Vehicle', 'Calendar_Year', \\\n",
    "                'Model_Year', 'Var1', 'Var2', 'Var3','Var4', 'Var5', \\\n",
    "                'Var6', 'Var7', 'Var8', 'NVVar1', 'NVVar2', 'NVVar3', 'NVVar4','OrdCat']\n",
    "full_transform = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), features_num),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown= 'ignore'), features_cat),\n",
    "])\n",
    "full_transform\n",
    "# handle_unknown= 'ignore'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b> <Centered_text> (1c) The data is highly imbalanced: more records contain zero claims than not. \n",
    "    When designing your predictive model, you need to account for this </Centered_text> </b>\n",
    "    \n",
    "To account for this I can use undersampling of the zero claims inorder to balance the data for the training set. Undersampling can be used as there is already a large data sample so instances from the over-represented zero claims class can be ignored. This will help the predictive model perform better when the claim amount is not zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the orginal dataset \n",
    "np.count_nonzero(ic_train_set['Claim_Amount']) \n",
    "ic_train_set.shape# The number of non zero claims\n",
    "# Used this value and the total number of claims to find the fraction of zero claims\n",
    "# needed to balance the data in the training set\n",
    "# Balanced the data using undersampling\n",
    "ic_train_set_sampled = ic_train_set.copy().drop(ic_train_set.query('Claim_Amount == 0').sample(frac=0.57).index)\n",
    "ic_train_set_sampled['Claim_Amount']\n",
    "ic_train_set_sampled.sample(10)\n",
    "ic_train_set_sampled\n",
    "# Before applying the transformation need to separate the target feature from the attributes\n",
    "ic_train_set_attributes = ic_train_set_sampled.drop('Claim_Amount', axis=1)\n",
    "ic_train_set_labels = ic_train_set_sampled['Claim_Amount']\n",
    "# Now apply and fit the transformer to the training data\n",
    "ic_train_set_attributes_prepared = full_transform.fit_transform(ic_train_set_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a further training and validation set from the original training set\n",
    "ic_train2_set, ic_val_set = train_test_split(ic_train_set, test_size=0.15, random_state=42)\n",
    "# Balancing the training data\n",
    "ic_train2_set_sampled = ic_train2_set.copy().drop(ic_train2_set.query('Claim_Amount == 0').sample(frac=0.57).index)\n",
    "ic_train2_set_sampled['Claim_Amount']\n",
    "ic_train2_set_sampled.sample(10)\n",
    "\n",
    "# These are just Xtrain, ytrain, Xtest, ytest\n",
    "ic_train2_set_attributes = ic_train2_set_sampled.drop('Claim_Amount', axis=1)\n",
    "ic_train2_set_labels = ic_train2_set_sampled['Claim_Amount']\n",
    "ic_val_set_attributes = ic_val_set.drop('Claim_Amount', axis=1)\n",
    "ic_val_set_labels = ic_val_set['Claim_Amount']\n",
    "# Fit tranform attributes in the training set and transform them in the validation set\n",
    "ic_train2_set_attributes_transformed = full_transform.fit_transform(ic_train2_set_attributes)\n",
    "ic_val_set_attributes_transformed = full_transform.transform(ic_val_set_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <Center> Performance using a single model </Center>  <br>\n",
    "(2a) Compute the performance of Linear Regression using gridsearch with at least 3 options for each parameter. \n",
    "Reporting the performance over the validation set </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Picking the parameters for gridsearch\n",
    "param_grid = {'fit_intercept':[True, False], 'normalize':[True, False], 'copy_X':[True, False]}\n",
    "grid = GridSearchCV(LinearRegression(), param_grid=param_grid, verbose=1, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Scoring only given as negative mean squared error\n",
    "# So need to get rid of the negative & then sqrt it to get rmse\n",
    "\n",
    "# grid.fit(ic_train_set_attributes_prepared, ic_train_set_labels)\n",
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226.55888465026382"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found the best parameters\n",
    "linear = LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
    "linear.fit(ic_train2_set_attributes_transformed, ic_train2_set_labels)\n",
    "ic_val_set_predictions = linear.predict(ic_val_set_attributes_transformed)\n",
    "# Now calcuating the rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_mod = np.sqrt(mean_squared_error(ic_val_set_labels, ic_val_set_predictions))\n",
    "error_mod\n",
    "# 226.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> (2b) Compute the performance of Ridge Regression using gridsearch with at least 3 options for each parameter. \n",
    "Reporting the performance over the validation set </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "param_grid = {'alpha':[0.0, 0.5, 1.0, 1.5, 2.0],'fit_intercept':[True, False], 'normalize':[True, False], 'copy_X':[True, False]}\n",
    "grid2 = GridSearchCV(Ridge(), param_grid=param_grid, verbose=1, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid2.fit(ic_train_set_attributes_prepared, ic_train_set_labels)\n",
    "# grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225.8271087877898"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found the best parameters\n",
    "ridge = Ridge(alpha=1.0, copy_X=True, fit_intercept=True, normalize=True)\n",
    "ridge.fit(ic_train2_set_attributes_transformed, ic_train2_set_labels)\n",
    "ic_val_set_predictions = ridge.predict(ic_val_set_attributes_transformed)\n",
    "error_mod = np.sqrt(mean_squared_error(ic_val_set_labels, ic_val_set_predictions))\n",
    "error_mod\n",
    "# 225.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> (2c) Compute the performance of Random Forests for regression using gridsearch with at least 3 options for each parameter. \n",
    "Reporting the performance over the validation set </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF_transform = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown= 'ignore'), features_cat),\n",
    "],remainder='passthrough')\n",
    "\n",
    "# Fit transform in the training set & then transform in the validation set\n",
    "ic_train2_set_attributes_RF_trans = RF_transform.fit_transform(ic_train2_set_attributes)\n",
    "ic_val_set_attributes_RF_trans = RF_transform.transform(ic_val_set_attributes)\n",
    "\n",
    "param_grid = {'n_estimators':[20, 50, 100, 200], 'max_samples':[500, 1000, 2000, 3000], 'max_depth':[3, 5, 10, 15]}\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid=param_grid, verbose=1, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid.fit(ic_train2_set_attributes_RF_trans, ic_train2_set_labels)\n",
    "# grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226.65649025729712"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found the best parameters\n",
    "forest = RandomForestRegressor(max_depth=3, max_samples=3000, n_estimators=200)\n",
    "forest.fit(ic_train2_set_attributes_transformed, ic_train2_set_labels)\n",
    "ic_val_set_predictions = forest.predict(ic_val_set_attributes_RF_trans )\n",
    "error_mod = np.sqrt(mean_squared_error(ic_val_set_labels, ic_val_set_predictions))\n",
    "error_mod\n",
    "# 227.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> (2d) Compute the performance of Gradient tree boosting for regression using gridsearch with at least 3 options for each parameter. Reporting the performance over the validation set </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "param_grid = {'n_estimators':[20, 50, 100, 200], 'max_depth':[3, 5, 10, 15],\n",
    "              'learning_rate':[0.1, 0.2, 0.3, 0.4]}\n",
    "grid = GridSearchCV(GradientBoostingRegressor(), param_grid=param_grid, verbose=1, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid.fit(ic_train2_set_attributes_RF_trans, ic_train2_set_labels)\n",
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227.40376332536425"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_boost = GradientBoostingRegressor(max_depth=3, learning_rate=0.1, n_estimators=20)\n",
    "grad_boost.fit(ic_train2_set_attributes_transformed, ic_train2_set_labels)\n",
    "ic_val_set_predictions = grad_boost.predict(ic_val_set_attributes_transformed)\n",
    "error_mod = np.sqrt(mean_squared_error(ic_val_set_labels, ic_val_set_predictions))\n",
    "error_mod\n",
    "# 228.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression performed the best with the lowest RMSE with the gradient boosting regressor performing the worst with the highest RMSE. However, all the single models performed very similarly with RMSE in the range of 225-228."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <Center> Performance using a combination of two models </Center> <br>\n",
    "(3a) The first model will be a binary classifier that will tell whether the claim was zero or different from zero.\n",
    "Compare the following classifiers: random forests for classification and gradient boosting for classification </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming a new binary variable assigning 1 as non zero and 0 as zero claims\n",
    "# For training data\n",
    "ic_train2_set_binary = ic_train2_set_sampled.copy()\n",
    "ic_train2_set_binary.query('Claim_Amount == 0')\n",
    "ic_train2_set_binary[\"Binary\"] = 1\n",
    "ic_train2_set_binary.loc[ic_train2_set_binary[\"Claim_Amount\"] == 0, \"Binary\"] = 0\n",
    "Xtrain2_binary = ic_train2_set_binary.drop('Claim_Amount', axis=1)\n",
    "# Testing it works\n",
    "ic_train2_set_binary.query('Claim_Amount != 0')\n",
    "ic_train2_set_binary.query('Claim_Amount == 0')\n",
    "# For validation data\n",
    "ic_val_set_binary = ic_val_set.copy()\n",
    "ic_val_set_binary[\"Binary\"] = 1\n",
    "ic_val_set_binary.loc[ic_val_set_binary[\"Claim_Amount\"] == 0, \"Binary\"] = 0\n",
    "Xval_binary = ic_val_set_binary.drop('Claim_Amount', axis=1)\n",
    "# Testing it works\n",
    "ic_train2_set_binary.query('Claim_Amount == 0')\n",
    "ic_val_set_binary.query('Claim_Amount != 0')\n",
    "\n",
    "# Now need to set the binary variable as y to make the classification\n",
    "# Not sure whether Claim_Amount is in xtrain or ytrain now\n",
    "Xtrain2 = Xtrain2_binary.iloc[:, :-1]\n",
    "ytrain2 = Xtrain2_binary.iloc[:, -1:]\n",
    "Xval = Xval_binary.iloc[:, :-1]\n",
    "yval = Xval_binary.iloc[:, -1:]\n",
    "# Transform \n",
    "Xtrain2_attributes = RF_transform.fit_transform(Xtrain2)\n",
    "Xval_attributes = RF_transform.fit_transform(Xval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = {'criterion':['entropy', 'gini'], 'n_estimators':[20, 50, 100, 200], 'max_depth':[3, 5, 10, 15],}\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, verbose=1, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid.fit(Xtrain2_attributes, ytrain2)\n",
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6607581306268901"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=50)\n",
    "forest_classifier.fit(Xtrain2_attributes, ytrain2.values.ravel())\n",
    "yval_predict = forest_classifier.predict(Xval_attributes)\n",
    "error_mod = np.sqrt(mean_squared_error(yval, yval_predict))\n",
    "error_mod\n",
    "# 0.661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "param_grid = {'loss':['deviance', 'exponential'], 'n_estimators':[20, 50, 100, 200], 'max_depth':[3, 5, 10, 15],\n",
    "             'criterion':['friedman_mse', 'mse', 'mae']}\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid=param_grid, verbose=2, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid.fit(Xtrain2_attributes, ytrain2)\n",
    "# grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6595700718942318"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_classifier = GradientBoostingClassifier(criterion='friedman_mse', loss='exponential', n_estimators=100, max_depth=3)\n",
    "grad_classifier.fit(Xtrain2_attributes, ytrain2.values.ravel())\n",
    "yval_predict = grad_classifier.predict(Xval_attributes)\n",
    "error_mod = np.sqrt(mean_squared_error(yval, yval_predict))\n",
    "error_mod\n",
    "# 0.653"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random forest classifer gave a slightly better performance with a marginally better accuracy when classifying whether the claims were zero or nonzero. The best hyperparameters were used for both instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> (3b) For the second model, if the claim was different from zero, train a regression model to predict the actual value of the claim. Compare the same models that you used in step 2 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the training set containing only non-zero values\n",
    "ic_train2_nonzero = ic_train2_set_binary.loc[ic_train2_set_binary[\"Binary\"] == 1].copy()\n",
    "ic_train2_nonzero = ic_train2_nonzero.drop('Binary', axis=1)\n",
    "Xtrain = ic_train2_nonzero.iloc[:, 0:23]\n",
    "ytrain = ic_train2_nonzero.iloc[:, 23]\n",
    "Xtrain_trans = full_transform.fit_transform(Xtrain)\n",
    "\n",
    "# For LinearRegression    \n",
    "param_grid = {'fit_intercept':[True, False], 'normalize':[True, False], 'copy_X':[True, False]}\n",
    "grid = GridSearchCV(LinearRegression(), param_grid=param_grid, verbose=1, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid.fit(Xtrain_trans, ytrain)\n",
    "# grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268.43831184741634"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_q3 = LinearRegression(copy_X=True, fit_intercept=True, normalize=False)\n",
    "linear_q3.fit(Xtrain_trans, ytrain)\n",
    "ic_val_set_predictions = linear_q3.predict(ic_val_set_attributes_transformed)\n",
    "# Now calcuating the rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_mod = np.sqrt(mean_squared_error(ic_val_set_labels, ic_val_set_predictions))\n",
    "error_mod\n",
    "#268.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Ridge Regression\n",
    "param_grid = {'alpha':[0.0, 0.5, 1.0, 1.5, 2.0],'fit_intercept':[True, False], 'normalize':[True, False], 'copy_X':[True, False]}\n",
    "grid = GridSearchCV(Ridge(), param_grid=param_grid, verbose=1, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid.fit(Xtrain_trans, ytrain)\n",
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.3442004025868"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_q3 = Ridge(alpha=1.0, copy_X=True, fit_intercept=True, normalize=True)\n",
    "ridge_q3.fit(Xtrain_trans, ytrain)\n",
    "ic_val_set_predictions = ridge_q3.predict(ic_val_set_attributes_transformed)\n",
    "error_mod = np.sqrt(mean_squared_error(ic_val_set_labels, ic_val_set_predictions))\n",
    "error_mod\n",
    "#263.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Random Forests for Regression\n",
    "\n",
    "# Only need to transform the new Xtrain data containing only nonzeros\n",
    "Xtrain_RF_trans = RF_transform.fit_transform(Xtrain)\n",
    "\n",
    "param_grid = {'n_estimators':[20, 50, 100, 200], 'max_samples':[500, 1000, 2000, 3000], 'max_depth':[3, 5, 10, 15]}\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid=param_grid, verbose=1, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid.fit(Xtrain_RF_trans, ytrain)\n",
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268.7952800237793"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_q3 = RandomForestRegressor(max_depth=3, max_samples=3000, n_estimators=200)\n",
    "forest_q3.fit(Xtrain_RF_trans, ytrain.values.ravel())\n",
    "ic_val_set_predictions = forest_q3.predict(ic_val_set_attributes_RF_trans)\n",
    "error_mod = np.sqrt(mean_squared_error(ic_val_set_labels, ic_val_set_predictions))\n",
    "error_mod\n",
    "#270.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For gradient tree boosting for regression\n",
    "param_grid = {'n_estimators':[20, 50, 100, 200], 'max_depth':[3, 5, 10, 15],\n",
    "              'learning_rate':[0.1, 0.2, 0.3, 0.4]}\n",
    "grid = GridSearchCV(GradientBoostingRegressor(), param_grid=param_grid, verbose=1, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid.fit(Xtrain_RF_trans, ytrain)\n",
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270.38821128144593"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_boost_q3 = GradientBoostingRegressor(max_depth=3, learning_rate=0.1, n_estimators=20)\n",
    "grad_boost_q3.fit(Xtrain_RF_trans, ytrain.values.ravel())\n",
    "ic_val_set_predictions = grad_boost_q3.predict(ic_val_set_attributes_RF_trans)\n",
    "error_mod = np.sqrt(mean_squared_error(ic_val_set_labels, ic_val_set_predictions))\n",
    "error_mod\n",
    "#270.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model for predicting the non-zero claims was also the Ridge regression model\n",
    "with the lowest root mean square error value. Linear Regression, Gradient tree boosting and random forest regressors\n",
    "had very similar error values in there predictions with root mean square errors ranging from 268-270.\n",
    "However, the Ridge regression model had a lower value of approximately 263. Once again, all the \n",
    "models performed very similarly which can be seen by the almost identical root mean square errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> (3c) Use the tandem model built from steps a and b, for predicting in the same validation data \n",
    "used in Step 2, and report the performance </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosting classifier and the ridge regression model will be use to form the tandem model.\n",
    "This is because they produced the best results in terms of accuracy for the classifier and rmse for the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241.71643091315218"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So need to use this on the training data containing zeros and nonzeros\n",
    "# First classifier predicts whether zero or nonzero\n",
    "# If nonzero then use ridge regression to predict the claim amount\n",
    "grad_classifier_tandem = GradientBoostingClassifier(criterion='friedman_mse', loss='exponential', n_estimators=100, max_depth=3)\n",
    "grad_classifier_tandem.fit(Xtrain2_attributes, ytrain2.values.ravel())\n",
    "yval_predict = grad_classifier_tandem.predict(Xval_attributes)\n",
    "ridge_tandem = Ridge(alpha=1.0, copy_X=True, fit_intercept=True, normalize=True)\n",
    "ridge_tandem.fit(Xtrain_trans, ytrain)\n",
    "yval_predictions = ridge_tandem.predict(ic_val_set_attributes_transformed)\n",
    "predictions = np.array([])\n",
    "c = 0\n",
    "for prediction in yval_predict:\n",
    "    if prediction == 1:\n",
    "        pred = yval_predictions[c]\n",
    "    elif prediction == 0:\n",
    "        pred = 0\n",
    "    c += 1\n",
    "    predictions = np.append(predictions,pred)\n",
    "error_mod = np.sqrt(mean_squared_error(ic_val_set_labels, predictions))\n",
    "error_mod\n",
    "# 241.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b> <Center> Report the performance of the best models over the test set </Center>  <br>\n",
    " (4) Compute the performance metric over the test set for the best model in Step 2  and the best model in Step 3. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model from step2 was the ridge regressor model, whilst the best model from step 3 was the tandem\n",
    "model formed by combining the gradient boosting classifier and the ridge regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209.60946241051226"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the test data into X and Y\n",
    "Xtest = ic_test_set.iloc[:, :-1]\n",
    "ytest = ic_test_set.iloc[:, -1:]\n",
    "ytest\n",
    "Xtest_transformed = full_transform.transform(Xtest)\n",
    "# step2 ridge regressor model\n",
    "ridge_test = Ridge(alpha=1.0, copy_X=True, fit_intercept=True, normalize=True)\n",
    "ridge_test.fit(ic_train_set_attributes_prepared, ic_train_set_labels)\n",
    "ridgeTest_predictions = ridge_test.predict(Xtest_transformed)\n",
    "error_mod = np.sqrt(mean_squared_error(ytest, ridgeTest_predictions))\n",
    "error_mod\n",
    "# 209.62\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to form the binary variable for the train and test data\n",
    "# train data\n",
    "ic_train_set_binary = ic_train_set_sampled.copy()\n",
    "ic_train_set_binary[\"Binary\"] = 1\n",
    "ic_train_set_binary.loc[ic_train_set_binary[\"Claim_Amount\"] == 0, \"Binary\"] = 0\n",
    "Xtrain_binary = ic_train_set_binary.drop('Claim_Amount', axis=1)\n",
    "# Testing it works\n",
    "ic_train_set_binary.query('Claim_Amount != 0')\n",
    "ic_train_set_binary.query('Claim_Amount == 0')\n",
    "# test data\n",
    "ic_test_set_binary = ic_test_set.copy()\n",
    "ic_test_set_binary[\"Binary\"] = 1\n",
    "ic_test_set_binary.loc[ic_test_set_binary[\"Claim_Amount\"] == 0, \"Binary\"] = 0\n",
    "Xtest_binary = ic_test_set_binary.drop('Claim_Amount', axis=1)\n",
    "# Testing it works\n",
    "ic_test_set_binary.query('Claim_Amount == 0')\n",
    "ic_test_set_binary.query('Claim_Amount != 0')\n",
    "\n",
    "# Now need to set the binary variable as y to make the classification\n",
    "Xtrain_classifier = Xtrain_binary.iloc[:, :-1]\n",
    "ytrain_classifier = Xtrain_binary.iloc[:, -1:]\n",
    "Xtest_classifier = Xtest_binary.iloc[:, :-1]\n",
    "ytest_classifier = Xtest_binary.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2308     120.54790\n",
       "22404      0.00000\n",
       "23397      0.00000\n",
       "25058      0.00000\n",
       "2664       0.00000\n",
       "           ...    \n",
       "19691      0.00000\n",
       "7752       0.00000\n",
       "17465     10.90208\n",
       "12912      0.00000\n",
       "8714      97.14479\n",
       "Name: Claim_Amount, Length: 4500, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic_train_nonzero = ic_train_set_binary.loc[ic_train_set_binary[\"Binary\"] == 1].copy()\n",
    "train = ic_train_nonzero.drop('Binary', axis=1)\n",
    "Xtrain_binary = train.iloc[:, :-1]\n",
    "ytrain_binary = train.iloc[:, -1:]\n",
    "Xtrain_binary_trans = full_transform.fit_transform(Xtrain_binary)\n",
    "Xtrain_attributes = RF_transform.fit_transform(ic_train_set_attributes)\n",
    "Xtest_attributes = RF_transform.transform(Xtest_classifier)\n",
    "Xtest_transformed.shape\n",
    "tandem_test = ic_test_set['Claim_Amount']\n",
    "tandem_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225.37055211970727"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_classifier_test = GradientBoostingClassifier(criterion='friedman_mse', loss='exponential', n_estimators=100, max_depth=3)\n",
    "grad_classifier_test.fit(Xtrain_attributes, ytrain_classifier.values.ravel())\n",
    "ytest_predict = grad_classifier_test.predict(Xtest_attributes)\n",
    "ridge_test = Ridge(alpha=1.0, copy_X=True, fit_intercept=True, normalize=True)\n",
    "ridge_test.fit(Xtrain_binary_trans, ytrain_binary)\n",
    "ytest_predictions = ridge_test.predict(Xtest_transformed)\n",
    "arr=np.array([])\n",
    "c=0\n",
    "for prediction in ytest_predict:\n",
    "    if prediction == 1:\n",
    "        pred=ytest_predictions[c]\n",
    "    elif prediction == 0:\n",
    "        pred = 0\n",
    "    c += 1\n",
    "    arr=np.append(arr,pred)\n",
    "    \n",
    "arr.shape\n",
    "error_mod = np.sqrt(mean_squared_error(tandem_test, arr))\n",
    "error_mod\n",
    "#225.499"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ridge regression model performed the best on the test data with a lower RMSE than the tandem model.\n",
    "However, the tandem model actually predicted the results with a greater accuracy by correctly predicting zero claim values so I will be using this model for predictions as the ridge regressor model was unable to predict zero claim values as successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b> <Center> Present your solution </Center> <br>\n",
    "   (5) Provide four interesting and meaningful observations/comments about your machine learning pipeline, \n",
    "    with minimum three sentences for each observation/comment. </b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One surprising outcome of the pipeline is that the single models provided the best performance by having a lower root-mean-squared-error (RMSE). This is unexpected as initially I expected the tandem model to perform the best as it uses a classifier to distinguish between the zero and nonzero claim accounts before applying the regression model. However, the accuracy of the classifiers appears to be a limiting factor with an accuracy of only 65% when predicting whether the claim was zero or nonzero. However even on the test set the ridge regression model performed slightly better than the tandem model with an RMSE of 209 compared to 210. <br> <br>\n",
    "Another notable observation is the similar performances of the regressions models on the validation data. There is not much difference between the models with RMSE with values ranging from 228 for the gradient boosting regressor to 225 for the ridge regression model. I expected a more notable difference between the linear models, for example I expected linear regression to have a higher value as I didn’t think the correlation would be precisely linear. <br> <br>\n",
    "Furthermore, as previously mentioned the two classifiers performed very similarly on the data as well with a very small difference in their accuracies. This was unexpected as the trees are built in different ways so I expected one of the classifiers to be more suitable for this dataset. For example, the random forest decision trees are built independently using bagging whilst gradient boosting builds one tree at a time using boosting. This is important as gradient boosting combines the results of the trees throughout the process while random forest combines the results using the majority rules once the process has finished. As a result, I expected the difference in approaches of the classifiers to lead to differing accuracies in their predictions. <br> <br>\n",
    "Additionally, the regression models performed worse in step 3b than in step 2. The difference between these instances was that in step 3b the models were only trained and focused on predicting nonzero values. This led to a worse performance than in step 2 where they were trained to provide predictions for the entire dataset of zero and nonzero claims. I believe the reasoning for this may simply just be because the models in step 3b were not trained to identify zero claim amounts and therefore struggled to predict these values in the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b> <Center> (6) Create a function that contains the best model you built from Steps 1 to 4 that we will use to \n",
    "assess the performance of your design over an independent test set </Center> </b> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_insurance_claim_predictor(test_data):\n",
    "    test_data = pd.read_csv('./data/test.csv', na_values=[\"?\" or \" \"], encoding='unicode_escape')\n",
    "    test_data\n",
    "    for i in test_data:\n",
    "        if(test_data[i].dtype == np.int64):\n",
    "            test_data[i] = test_data[i].astype('float64')\n",
    "    for i in test_data:\n",
    "        if(test_data[i].dtype == np.float64):\n",
    "            test_data[i].fillna(test_data[i].median(), inplace=True)\n",
    "        else:\n",
    "            test_data[i].fillna(test_data[i].mode()[0], inplace=True)\n",
    "    test_data = test_data.drop(['Cat1','Cat2', 'Cat4', 'Cat5', 'Cat7', 'Cat10', \\\n",
    "                                            'Cat11', 'Cat12', 'Blind_Submodel','Blind_Make','Blind_Model'], axis=1)\n",
    "    test_data_binary = test_data.copy()\n",
    "    Xtest_data = test_data.drop('Claim_Amount', axis=1)\n",
    "    Xtest_data\n",
    "    Xtest_attributes = full_transform.transform(Xtest_data)\n",
    "    test_data_binary[\"Binary\"] = 1\n",
    "    test_data_binary.loc[test_data_binary[\"Claim_Amount\"] == 0, \"Binary\"] = 0\n",
    "    Xtest_classifier = test_data_binary.drop('Claim_Amount', axis=1)\n",
    "    Xtest_classifier = test_data_binary.iloc[:, 0:23]\n",
    "    Xtest_classifier\n",
    "    ytest_classifier = test_data_binary.iloc[:, -1:]\n",
    "    ytest_classifier\n",
    "    Xtest_class_trans = RF_transform.transform(Xtest_classifier)\n",
    "        \n",
    "    ytest_predict = grad_classifier_test.predict(Xtest_class_trans)\n",
    "    ytest_predictions = ridge_test.predict(Xtest_attributes)\n",
    "    prediction = np.array([])\n",
    "    c = 0\n",
    "    for predictions in ytest_predict:\n",
    "        if predictions == 1:\n",
    "            pred = ytest_predictions[c]\n",
    "        elif predictions == 0:\n",
    "            pred = 0\n",
    "        c += 1\n",
    "        prediction = np.append(prediction,pred)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = pd.read_csv('./data/test.csv', na_values=[\"?\" or \" \"], encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euan\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  warnings.warn(\"Given feature/column names or counts do not match \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.        , 246.22225672, 157.41175612, 254.43972888,\n",
       "       233.90515253, 160.99961676,   0.        , 171.47998238,\n",
       "       186.11475579])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = my_insurance_claim_predictor(Xtest)\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
